# Project Description   
**FILES / Project is divided into 5 parts:**
1. ENCE_3503_Spring_2025_Web_Scraper_Team_4 - Scraped data from the website **https://www.hellojob.az/** with the help of class names and inspection of the website
 with the help of **beautifulsoup4**.   
2. scraped_data_team_4.csv - Scraped data size with the attributes of 293 rows and 11 columns.   
3. ENCE_3503_Spring_2025_EDA_Team_4 - Appled EDA & Preprocessing steps on the raw data and cleaning it.  
4. processed_data_team_4.csv - Preprocessed and clean data obtained after the 3rd steps done.  
5. ENCE_3503_Spring_2025_ML_Team_4 - Applied ML algorithms eg., Random Forest Classifier... to give some predictions on the cleaned data by training
   and getting some insights of the data with the means of avg salary predicted...

**Steps:**
After scrapeing job listings from HelloJob.az, we extracted the key details such as job title, company name, location, date, and job URL, and saved the results into a structured CSV file for further analysis.  

**Features obtained:**
1. Scraped multiple pages of job listings  
2. Extracted job details such as: Job Title, Company, Location, Date Posted, Direct Job URL, Stored results in a CSV format using pandas

**COMPILATION & RUN OF THE PROGRAM:**  
All codes were written and used only in Jupyter Notebook .ipynb files.    
For running the code first make sure you have installed the following libraries (you can add based on the code as you need):   
(`pip install requests beautifulsoup4 pandas)    

(`pip install pandas)... 

**Scraped Data**   
![image](https://github.com/user-attachments/assets/84663cc3-26bb-4592-b96d-d94ab27d4f73)

**Preprocessed Data**  
![image](https://github.com/user-attachments/assets/6c5529e4-f1ee-473a-8daf-737de78d8a6c)

**OBTAINED RESULTS:**

![image](https://github.com/user-attachments/assets/5ce07cf9-f408-4d39-9c32-b54c4682b9a4)

![image](https://github.com/user-attachments/assets/18efdaa4-4bb2-4355-8dd2-406e6e053c76) 
